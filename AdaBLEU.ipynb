{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AdaBLEU.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"K-bhJZRzPlZG"},"source":["***1.adaBLEU with t2t BLEU (0-100)***"]},{"cell_type":"code","metadata":{"id":"iKA4uxr_qnw7","colab":{"base_uri":"https://localhost:8080/","height":88},"outputId":"ae6cc07c-ceec-40d5-b65e-95ce33f8d0d4"},"source":["!t2t-bleu  --translation=/content/urdu_translated_new_dep.txt --reference=/content/urdu_ref_new_dep.txt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-07-05 04:01:31.441078: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","BLEU_uncased =  22.80\n","BLEU_cased =  22.80\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LXTEreQndJqQ"},"source":["**1.1OVERALL TEXT BLEU**"]},{"cell_type":"code","metadata":{"id":"dEnOkOA_a3Bu","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"c403ec9a-0ee1-4afd-8515-0fa8bb38d400"},"source":["import subprocess as sub\n","p = sub.Popen(['t2t-bleu' ,'--translation=/content/Translated_URDU.txt', '--reference=/content/Reference_URDU.txt', '--worker_gpu=1'],stdout=sub.PIPE,stderr=sub.PIPE)\n","output, errors = p.communicate()\n","print (output)\n","import re\n","regex=r\"[0-9]+.[0-9]+\"\n","x=re.findall(regex,str(output))\n","x=str(x[0])\n","text_bleu=float(x)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["b'BLEU_uncased =  12.06\\nBLEU_cased =  12.06\\n'\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"61xoxtnhdPVs"},"source":["**1.2OVERALL POS BLEU**"]},{"cell_type":"code","metadata":{"id":"5LmBYfQFcQiD","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"e4990d0b-e462-459d-e632-357a1b651cbd"},"source":["import subprocess as sub\n","p = sub.Popen(['t2t-bleu' ,'--translation=/content/urdu_translated_pos.txt', '--reference=/content/urdu_reference_pos.txt', '--worker_gpu=1'],stdout=sub.PIPE,stderr=sub.PIPE)\n","output, errors = p.communicate()\n","print (output)\n","import re\n","regex=r\"[0-9]+.[0-9]+\"\n","x=re.findall(regex,str(output))\n","x=str(x[0])\n","pos_bleu=float(x)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["b'BLEU_uncased =  27.09\\nBLEU_cased =  27.09\\n'\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"idLnM4q3dTwg"},"source":["**1.3OVERALL DEP BLEU**"]},{"cell_type":"code","metadata":{"id":"XTlfwW_zcREu","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"469ed513-0932-45d7-b525-a192c8ba3595"},"source":["import subprocess as sub\n","p = sub.Popen(['t2t-bleu' ,'--translation=/content/urdu_translated_dep.txt', '--reference=/content/urdu_reference_dep.txt', '--worker_gpu=1'],stdout=sub.PIPE,stderr=sub.PIPE)\n","output, errors = p.communicate()\n","print (output)\n","import re\n","regex=r\"[0-9]+.[0-9]+\"\n","x=re.findall(regex,str(output))\n","x=str(x[0])\n","dep_bleu=float(x)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["b'BLEU_uncased =  22.80\\nBLEU_cased =  22.80\\n'\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TtMg-C6vP5L6"},"source":["**AdaBLEU score**"]},{"cell_type":"code","metadata":{"id":"qBs_rENucO9H","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"5defbe20-d86d-4770-cffa-c516afe9a23b"},"source":["flex=0.0\n","flex=((((6*float(pos_bleu))+(2*float(dep_bleu))))+(2*float(text_bleu)))/10\n","print(flex)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["23.226\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Qh6bycfZQEBW"},"source":["**2. AdaBLEU using NLTK BLEU(0-1**"]},{"cell_type":"markdown","metadata":{"id":"HHJ0xlzSacmO"},"source":["**2.1TEXT BLEU**"]},{"cell_type":"code","metadata":{"id":"spp8tFFH7S2G"},"source":["from nltk import word_tokenize\n","from nltk.translate.bleu_score import sentence_bleu\n","translated_file = \"/content/tr.txt\"\n","reference_file = \"/content/re.txt\"\n","f5 = open('/content/o1.txt', \"a+\")\n","with open(translated_file, \"r\") as f1, open(reference_file, \"r\") as f2:\n","  lines1 = [line.rstrip('\\n') for line in f1]\n","  #print(lines1)\n","  lines2 = [line.rstrip('\\n') for line in f2]\n","  #print(lines2)\n","  for l1,l2 in zip(lines1,lines2):\n","    tokens_ref=[word_tokenize(l2)]\n","    tokens_translate=word_tokenize(l1)\n","    score = sentence_bleu(tokens_ref, tokens_translate, weights=(0.25, 0.25, 0.25, 0.25))\n","    f5.write(str(score)+'\\n')\n","f5.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M5a-sPCEagaQ"},"source":["**2.2 POS BLEU**"]},{"cell_type":"code","metadata":{"id":"4WWnIwSCaYZ4"},"source":["from nltk import word_tokenize\n","from nltk.translate.bleu_score import sentence_bleu\n","translated_POS_file = \"/content/drive/My Drive/t2.txt\"\n","reference_POS_file = \"/content/drive/My Drive/r1.txt\"\n","f5 = open('/content/drive/My Drive/output_pos_bleu.txt', \"a+\")\n","with open(translated_file, \"r\") as f1, open(reference_file, \"r\") as f2:\n","  lines1 = [line.rstrip('\\n') for line in f1]\n","  #print(lines1)\n","  lines2 = [line.rstrip('\\n') for line in f2]\n","  #print(lines2)\n","  for l1,l2 in zip(lines1,lines2):\n","    tokens_ref=[word_tokenize(l2)]\n","    tokens_translate=word_tokenize(l1)\n","    score = sentence_bleu(tokens_ref, tokens_translate, weights=(0.25, 0.25, 0.25, 0.25))\n","    f5.write(str(score)+'\\n')\n","f5.close()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kVGmDEXdalfk"},"source":["**2.3 DP BLEU**"]},{"cell_type":"code","metadata":{"id":"JTqdLnRvaXjv"},"source":["from nltk import word_tokenize\n","from nltk.translate.bleu_score import sentence_bleu\n","translated_DP_file = \"/content/drive/My Drive/t2.txt\"\n","reference_DP_file = \"/content/drive/My Drive/r1.txt\"\n","f5 = open('/content/drive/My Drive/output_DP_bleu.txt', \"a+\")\n","with open(translated_file, \"r\") as f1, open(reference_file, \"r\") as f2:\n","  lines1 = [line.rstrip('\\n') for line in f1]\n","  #print(lines1)\n","  lines2 = [line.rstrip('\\n') for line in f2]\n","  #print(lines2)\n","  for l1,l2 in zip(lines1,lines2):\n","    tokens_ref=[word_tokenize(l2)]\n","    tokens_translate=word_tokenize(l1)\n","    score = sentence_bleu(tokens_ref, tokens_translate, weights=(0.25, 0.25, 0.25, 0.25))\n","    f5.write(str(score)+'\\n')\n","f5.close()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z6bMvVLkSaTL"},"source":["**AdaBLEU**"]},{"cell_type":"code","metadata":{"id":"Hr6Ab-rGP-lI"},"source":["translated_dep_file = \"/content/DEP_BLEU_UR-2.txt\"\n","translated_pos_file = \"/content/POS_BLEU_UR-2.txt\"\n","translated_bleu_file = \"/content/BLEU_UR_27.txt\"\n","f5 = open('/content/FLEXIBLEU.txt', \"a+\")\n","flex=0.0\n","with open(translated_bleu_file, \"r\") as f1, open(translated_pos_file, \"r\") as f2,  open(translated_dep_file, \"r\") as f6:\n","  lines1 = [line.rstrip('\\n') for line in f1]\n","  lines2 = [line.rstrip('\\n') for line in f2]\n","  lines3 = [line.rstrip('\\n') for line in f6]\n","  for l1,l2,l3 in zip(lines1,lines2,lines3):\n","    flex=0.0\n","    flex=((((6*float(l2))+(2*float(l3))))+(2*float(l1)))/10\n","    f5.write(str(flex)+'\\n')\n","f5.close()"],"execution_count":null,"outputs":[]}]}